{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Используя файл Lesson_3_extended.ipynb (он в web3.zip в материалах):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1*. Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным.\n",
    "3. Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba).\n",
    "4. Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5*. Реализуйте функции для подсчета Accuracy, матрицы ошибок, точности и полноты, а также F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Могла ли модель переобучиться? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([ [   1,    1,  500,    1],\n",
    "               [   1,    1,  700,    1],\n",
    "               [   1,    2,  750,    2],\n",
    "               [   1,    5,  600,    1],\n",
    "               [   1,    3, 1450,    2],\n",
    "               [   1,    0,  800,    1],\n",
    "               [   1,    5, 1500,    3],\n",
    "               [   1,   10, 2000,    3],\n",
    "               [   1,    1,  450,    1],\n",
    "               [   1,    2, 1000,    2]], dtype=np.float64)\n",
    "\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.40632829,  0.27334007,  1.05328664, -0.15160214,  0.46496879,\n",
       "        0.32970504,  1.12205628,  0.17529032,  0.43957535,  0.88705137])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scale(x):\n",
    "    res = (x - x.mean()) / x.std()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_st = X.copy()\n",
    "X_st[:, 2] = standard_scale(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        , -0.97958969,  1.        ],\n",
       "       [ 1.        ,  1.        , -0.56713087,  1.        ],\n",
       "       [ 1.        ,  2.        , -0.46401617,  2.        ],\n",
       "       [ 1.        ,  5.        , -0.77336028,  1.        ],\n",
       "       [ 1.        ,  3.        ,  0.97958969,  2.        ],\n",
       "       [ 1.        ,  0.        , -0.36090146,  1.        ],\n",
       "       [ 1.        ,  5.        ,  1.08270439,  3.        ],\n",
       "       [ 1.        , 10.        ,  2.11385144,  3.        ],\n",
       "       [ 1.        ,  1.        , -1.08270439,  1.        ],\n",
       "       [ 1.        ,  2.        ,  0.05155735,  2.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logloss(y, y_pred):\n",
    "    err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60020715, 0.5679127 , 0.74140552, 0.46217189, 0.61419225,\n",
       "       0.58168761, 0.75436994, 0.54371071, 0.60815784, 0.7082813 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = sigmoid(model.predict(X))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(X, y, iterations, eta=1e-4):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        z = np.dot(X, W)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        \n",
    "        dQ = 1/n * X.T @ (y_pred - y)\n",
    "        W -= eta * dQ\n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(i, W, err)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1*. Модифицируем функцию calc_logloss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Идея модификации функции в том, чтобы передавать не 0 или 1, а крайне близкое к ним значение,\n",
    "например 0.000001 / 0.999999. Не считать ошибку на примерах, к примеру, с нулями, которые наиболее\n",
    "важные для нас-это грубая ошибка''' \n",
    "\n",
    "def calc_logloss_mod(y, y_pred):\n",
    "    y_pred_res=np.where(y_pred==1, y_pred-1e-09, np.where(y_pred==0, y_pred+1e-09, y_pred))\n",
    "    err = - np.mean(y * np.log(y_pred_res) + (1.0 - y) * np.log(1.0 - y_pred_res))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4842439777208694"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Чтобы проверить работоспособность функции, заменим рандомные значения в векторе предсказанных значений на нули и единицы\n",
    "\n",
    "y_pred_demo = np.array([0.60020715, 0. , 0.74140552, 0.46217189, 1.,\n",
    "       0.58168761, 0.75436994, 0.54371071, 0., 0.7082813])\n",
    "\n",
    "calc_logloss_mod(y, y_pred_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-7d5907c1794a>:2: RuntimeWarning: divide by zero encountered in log\n",
      "  err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
      "<ipython-input-7-7d5907c1794a>:2: RuntimeWarning: invalid value encountered in multiply\n",
      "  err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Немодифицированная (исходная) функция при всех равных возвращает ошибку (nan)\n",
    "\n",
    "calc_logloss(y, y_pred_demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(X, y, verbose=False, eta=1e-4, tol=0.00001):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    min_err = float('inf')  # зададим бесконечно большое начальное значение ошибки\n",
    "    n_iter = 0  # отслеживаем количество итераций\n",
    "    view_ind = 10**(-np.log10(tol)-2) if -np.log10(tol)-2>=1 else 1 # параметр кратности вывода промежуточных результатов\n",
    "    stop_check = True\n",
    "    errors = []  # добавим для визуализации кривой обучения\n",
    "    \n",
    "    while stop_check:\n",
    "        n_iter += 1\n",
    "        z = np.dot(X, W)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss_mod(y, y_pred) # заменим на модифицированную нами ранее функцию\n",
    "        errors.append(err)\n",
    "        if min_err - err > tol:  # контролируем текущее значение ошибки\n",
    "            min_err = err\n",
    "        else:  # если снижение прекратилось, останавливаемся.\n",
    "            print(\n",
    "                f'Stop descent! iteration: {n_iter}, weights: {W}, logloss: {min_err}')\n",
    "            stop_check = False\n",
    "        dQ = 1/n * X.T @ (y_pred - y)\n",
    "        W -= eta * dQ\n",
    "        if verbose:\n",
    "            if n_iter % view_ind == 0:\n",
    "                print(n_iter, W, err)\n",
    "    return W, min_err, n_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь подберем лучшие параметры eta для модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_params(X,y,args):\n",
    "    best_params=[]\n",
    "    for arg in args:\n",
    "        W,err,n_iter = eval_model(X, y, eta=arg)\n",
    "        best_params.append((arg,err,n_iter))\n",
    "    best_params.sort(key=lambda x:x[1])\n",
    "    print(f'best - alpha: {best_params[0][0]},\\nresults:\\nerr: {best_params[0][1]},\\nn_iter: {best_params[0][2]}')\n",
    "    return best_params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop descent! iteration: 5507, weights: [-7.85409116 -1.16596006 -1.51053115  6.85817166], logloss: 0.2644646885841898\n",
      "Stop descent! iteration: 5473, weights: [-11.26122492  -1.42607616  -2.57916356   9.54824479], logloss: 0.227225466097774\n",
      "Stop descent! iteration: 5668, weights: [-14.17179784  -1.67221877  -3.45623879  11.89872411], logloss: 0.2026696681492856\n",
      "Stop descent! iteration: 5684, weights: [-16.49351659  -1.87498924  -4.14297044  13.78351526], logloss: 0.18614618122887375\n",
      "Stop descent! iteration: 5588, weights: [-18.35029116  -2.03943006  -4.68623881  15.29282887], logloss: 0.17451429964096338\n",
      "Stop descent! iteration: 5449, weights: [-19.88389849  -2.17629563  -5.13166996  16.53977688], logloss: 0.16583588446774875\n",
      "Stop descent! iteration: 4, weights: [ 0.20089413 -0.9754314   0.73619273  1.29296406], logloss: 0.5606348884004944\n",
      "Stop descent! iteration: 4, weights: [ 0.16967474 -1.19422836  0.72412524  1.26942358], logloss: 0.6239910394972162\n",
      "Stop descent! iteration: 4, weights: [ 0.14045695 -1.40730485  0.71387582  1.25013553], logloss: 0.7031038918728882\n",
      "best - alpha: 0.6,\n",
      "results:\n",
      "err: 0.16583588446774875,\n",
      "n_iter: 5449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6, 0.16583588446774875, 5449)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas=np.arange(1,10)/10\n",
    "best_params=get_best_params(X_st,y,alphas)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший результат получаем при eta=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 [-8.22705654 -1.19179224 -1.63103389  7.14617725] 0.2597559875895107\n",
      "2000 [-11.81693228  -1.47202752  -2.74842535   9.99506855] 0.2221605978051024\n",
      "3000 [-14.60325068  -1.70958893  -3.58457685  12.24861365] 0.19942508537234374\n",
      "4000 [-16.96660182  -1.91673038  -4.28184084  14.16798183] 0.1830620510486847\n",
      "5000 [-19.03415014  -2.10036075  -4.88520289  15.84885732] 0.17054733057426585\n",
      "Stop descent! iteration: 5449, weights: [-19.88389849  -2.17629563  -5.13166996  16.53977688], logloss: 0.16583588446774875\n"
     ]
    }
   ],
   "source": [
    "W = eval_model(X_st, y, eta=0.6, tol=0.00001, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(x, w): \n",
    "    pred_proba = sigmoid(np.dot(x, w))\n",
    "    return pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 [-8.22705654 -1.19179224 -1.63103389  7.14617725] 0.2597559875895107\n",
      "2000 [-11.81693228  -1.47202752  -2.74842535   9.99506855] 0.2221605978051024\n",
      "3000 [-14.60325068  -1.70958893  -3.58457685  12.24861365] 0.19942508537234374\n",
      "4000 [-16.96660182  -1.91673038  -4.28184084  14.16798183] 0.1830620510486847\n",
      "5000 [-19.03415014  -2.10036075  -4.88520289  15.84885732] 0.17054733057426585\n",
      "Stop descent! iteration: 5449, weights: [-19.88389849  -2.17629563  -5.13166996  16.53977688], logloss: 0.16583588446774875\n"
     ]
    }
   ],
   "source": [
    "W,_err,_it = eval_model(X_st, y, eta=0.6, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.79075791e-01, 6.84786993e-02, 9.99986668e-01, 3.50840343e-05,\n",
       "       8.37531436e-01, 1.83584725e-01, 9.99998324e-01, 5.33913207e-02,\n",
       "       5.08932298e-01, 9.99812077e-01])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = calc_pred_proba(X_st, W)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(x,w, prob_lim=0.5):    # установим порог вероятности, при превышении которого, объект будет относиться к классу 1\n",
    "    pred_proba = sigmoid(np.dot(x, w))\n",
    "    pred=np.zeros_like(pred_proba)\n",
    "    for idx, prob in enumerate(pred_proba):\n",
    "        if prob>prob_lim:\n",
    "            pred[idx]=1\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 1., 0., 1., 0., 1., 1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=calc_pred(X_st, W)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для проверки верности самописных функций импортируем следующие метрики из библиотеки sklearn\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def east_accuracy(real, pred):\n",
    "    all_res=len(real)\n",
    "    trues=0\n",
    "    for i in range(all_res):\n",
    "        trues += int(real[i]==pred[i])\n",
    "    return trues/all_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "east_accuracy(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверка\n",
    "\n",
    "accuracy_score(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def east_confusion_matrix(real, pred):\n",
    "    n_classes=len(np.unique(real))\n",
    "    all_res=len(real)\n",
    "    conf_matr=np.zeros((n_classes,n_classes), dtype='int')\n",
    "    for i in range(all_res):\n",
    "        conf_matr[int(real[i])][int(pred[i])] += 1\n",
    "    return conf_matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0],\n",
       "       [0, 5]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "east_confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0],\n",
       "       [0, 5]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверка\n",
    "\n",
    "confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def east_precision(real, pred):\n",
    "    tn, fp, fn, tp = east_confusion_matrix(real, pred).ravel()\n",
    "    return tp/(tp+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "east_precision(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверка\n",
    "\n",
    "precision_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def east_recall(real, pred):\n",
    "    tn, fp, fn, tp = east_confusion_matrix(real, pred).ravel()\n",
    "    return tp/(tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "east_recall(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def east_f1(real, pred, beta=1):\n",
    "    return (1+beta**2)*east_precision(real, pred)*east_recall(y,y_pred)/(beta**2*east_precision(real, pred)+east_recall(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "east_f1(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверка\n",
    "\n",
    "f1_score(y,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно предположить, что модель могла переобучиться, потому как модель логистической регрессии склонна к переобучению, в следствии того что мы используем сигмоиду для того, чтобы преобразовать в вероятность предсказания линейной модели. А из-за того, что сигмоида не имеет максимума и минимума, а только асимптоты в 0 и 1, градиентный спуск не может достичь оптимального решения с помощью градиентных шагов доводя веса до всё более экстремальных значений, пытаясь достичь нулевых потерь. При большой размерности данных вероятность этого, скорее всего, еще больше увеличится. Чтобы этого избежать в качестве способа регуляризации можно использовать ранний останов работы модели, а так же L1 и L2-регуляризацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
